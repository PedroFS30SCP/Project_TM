{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "543e9427",
   "metadata": {},
   "source": [
    "# üí¨ TMCD ‚Äì Trabalho Final\n",
    "## An√°lise de Sentimentos em Reviews de Filmes\n",
    "\n",
    "### üë• Grupo Trab-grupo-30\n",
    "- **Rafael Alexandre Dias Andorinha**, n¬∫ 131000  \n",
    "- **Pedro Fonte Santa**, n¬∫ 105306  \n",
    "\n",
    "---\n",
    "\n",
    "üìÖ **Data de entrega:** 26 de abril  \n",
    "\n",
    "üìä **Objetivo deste script:**\n",
    "fmoewfew\n",
    "\n",
    "---\n",
    "\n",
    "# üóÇÔ∏è Dataset: IMDB Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fe29492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pedrofs/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Downloads necess√°rios\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfecfe6",
   "metadata": {},
   "source": [
    "### üîπ 1. Carregar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e705981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is your typical cheerful and colorful MGM...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a another reviewer states Hanna's War is an...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One of the best \"Amitabh comeback\" movies I li...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peter Sollett has created an endearing portrai...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The film is not visually stunning in the conve...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  This is your typical cheerful and colorful MGM...   pos\n",
       "1  As a another reviewer states Hanna's War is an...   pos\n",
       "2  One of the best \"Amitabh comeback\" movies I li...   pos\n",
       "3  Peter Sollett has created an endearing portrai...   pos\n",
       "4  The film is not visually stunning in the conve...   pos"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caminhos para os ficheiros\n",
    "train_path = '../dataset/imdb_reviews_train.csv'\n",
    "test_path = '../dataset/imdb_reviews_test.csv'\n",
    "\n",
    "# Carregar os datasets\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "# Visualizar estrutura\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdca9f27",
   "metadata": {},
   "source": [
    "### üîπ 2. Fun√ß√£o auxiliar para avaliar os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e40b3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalia√ß√£o\n",
    "def avaliar_resultados(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, pos_label='pos')\n",
    "    rec = recall_score(y_true, y_pred, pos_label='pos')\n",
    "    f1 = f1_score(y_true, y_pred, pos_label='pos')\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.3f}\")\n",
    "    print(f\"Precis√£o: {prec:.3f}\")\n",
    "    print(f\"Recall: {rec:.3f}\")\n",
    "    print(f\"F1 Score: {f1:.3f}\")\n",
    "\n",
    "    return {'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1': f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1c8e30",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Experi√™ncia 1 ‚Äî Baseline (apenas lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7fc31b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Resultados ‚Äî Experi√™ncia 1 (baseline, apenas lowercase)\n",
      "Accuracy: 0.882\n",
      "Precis√£o: 0.884\n",
      "Recall: 0.879\n",
      "F1 Score: 0.882\n"
     ]
    }
   ],
   "source": [
    "# Pr√©-processamento simples\n",
    "df_train['text_exp1'] = df_train['text'].str.lower()\n",
    "df_test['text_exp1'] = df_test['text'].str.lower()\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer1 = TfidfVectorizer()\n",
    "X_train1 = vectorizer1.fit_transform(df_train['text_exp1'])\n",
    "X_test1 = vectorizer1.transform(df_test['text_exp1'])\n",
    "\n",
    "# Modelo\n",
    "modelo1 = LogisticRegression(max_iter=1000)\n",
    "modelo1.fit(X_train1, df_train['label'])\n",
    "y_pred1 = modelo1.predict(X_test1)\n",
    "\n",
    "# Avalia√ß√£o\n",
    "print(\"üìä Resultados ‚Äî Experi√™ncia 1 (baseline, apenas lowercase)\")\n",
    "resultados_exp1 = avaliar_resultados(df_test['label'], y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654948e5",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Experi√™ncia 2 ‚Äî Com stopwords e pontua√ß√£o removida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fab7e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©-processamento com stopwords e pontua√ß√£o removida\n",
    "stop_words = set(stopwords.words('english'))\n",
    "pontuacao = set(string.punctuation)\n",
    "\n",
    "def preprocessar_texto_limpo(texto):\n",
    "    texto = texto.lower()\n",
    "    tokens = wordpunct_tokenize(texto)\n",
    "    tokens_filtrados = [t for t in tokens if t not in pontuacao and t not in stop_words]\n",
    "    return ' '.join(tokens_filtrados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c42e0c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Resultados ‚Äî Experi√™ncia 2 (com stopwords e pontua√ß√£o removida)\n",
      "Accuracy: 0.882\n",
      "Precis√£o: 0.882\n",
      "Recall: 0.881\n",
      "F1 Score: 0.882\n"
     ]
    }
   ],
   "source": [
    "# Pr√©-processar texto\n",
    "df_train['text_exp2'] = df_train['text'].apply(preprocessar_texto_limpo)\n",
    "df_test['text_exp2'] = df_test['text'].apply(preprocessar_texto_limpo)\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer2 = TfidfVectorizer()\n",
    "X_train2 = vectorizer2.fit_transform(df_train['text_exp2'])\n",
    "X_test2 = vectorizer2.transform(df_test['text_exp2'])\n",
    "\n",
    "# Modelo\n",
    "modelo2 = LogisticRegression(max_iter=1000)\n",
    "modelo2.fit(X_train2, df_train['label'])\n",
    "y_pred2 = modelo2.predict(X_test2)\n",
    "\n",
    "# Avalia√ß√£o\n",
    "print(\"üìä Resultados ‚Äî Experi√™ncia 2 (com stopwords e pontua√ß√£o removida)\")\n",
    "resultados_exp2 = avaliar_resultados(df_test['label'], y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484e62f2",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Experi√™ncia 3 ‚Äî Com stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad49eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©-processamento com stemming\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocessar_texto_stemming(texto):\n",
    "    texto = texto.lower()\n",
    "    tokens = wordpunct_tokenize(texto)\n",
    "    tokens = [t for t in tokens if t not in pontuacao and t not in stop_words]\n",
    "    stems = [stemmer.stem(t) for t in tokens]\n",
    "    return ' '.join(stems)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "527d0d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Resultados ‚Äî Experi√™ncia 3 (com stemming)\n",
      "Accuracy: 0.880\n",
      "Precis√£o: 0.880\n",
      "Recall: 0.879\n",
      "F1 Score: 0.879\n"
     ]
    }
   ],
   "source": [
    "# Pr√©-processar texto com stemming\n",
    "df_train['text_exp3'] = df_train['text'].apply(preprocessar_texto_stemming)\n",
    "df_test['text_exp3'] = df_test['text'].apply(preprocessar_texto_stemming)\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer3 = TfidfVectorizer()\n",
    "X_train3 = vectorizer3.fit_transform(df_train['text_exp3'])\n",
    "X_test3 = vectorizer3.transform(df_test['text_exp3'])\n",
    "\n",
    "# Modelo\n",
    "modelo3 = LogisticRegression(max_iter=1000)\n",
    "modelo3.fit(X_train3, df_train['label'])\n",
    "y_pred3 = modelo3.predict(X_test3)\n",
    "\n",
    "# Avalia√ß√£o\n",
    "print(\"üìä Resultados ‚Äî Experi√™ncia 3 (com stemming)\")\n",
    "resultados_exp3 = avaliar_resultados(df_test['label'], y_pred3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae82d30",
   "metadata": {},
   "source": [
    "### üìà Compara√ß√£o final das experi√™ncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d0913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar DataFrame com resultados\n",
    "valores = [\n",
    "    list(resultados_exp1.values()),\n",
    "    list(resultados_exp2.values()),\n",
    "    list(resultados_exp3.values())\n",
    "]\n",
    "\n",
    "experiencias = ['Exp. 1\\nBaseline', 'Exp. 2\\n+ Stopwords', 'Exp. 3\\n+ Stemming']\n",
    "metricas = ['Accuracy', 'Precis√£o', 'Recall', 'F1 Score']\n",
    "\n",
    "df_resultados = pd.DataFrame(valores, index=experiencias, columns=metricas)\n",
    "\n",
    "# Gr√°fico\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_resultados.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Compara√ß√£o de desempenho entre experi√™ncias de ML')\n",
    "plt.ylabel('Valor da M√©trica')\n",
    "plt.ylim(0.5, 0.9)\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4b17eb",
   "metadata": {},
   "source": [
    "### üìä Resultados das Experi√™ncias com Modelos de Aprendizagem Autom√°tica\n",
    "\n",
    "| Experi√™ncia            | Accuracy | Precis√£o | Recall | F1 Score | Observa√ß√µes                                 |\n",
    "|------------------------|----------|----------|--------|----------|---------------------------------------------|\n",
    "| Exp. 1 - Baseline      | 0.882    | 0.884    | 0.879  | 0.882    | Apenas lowercase                            |\n",
    "| Exp. 2 - + Stopwords   | 0.882    | 0.882    | 0.881  | 0.882    | Remo√ß√£o de stopwords e pontua√ß√£o            |\n",
    "| Exp. 3 - + Stemming    | 0.880    | 0.880    | 0.879  | 0.879    | Pr√©-processamento com stemming              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d81218",
   "metadata": {},
   "source": [
    "### üîé Fontes e materiais de apoio utilizados na Tarefa 2.4\n",
    "\n",
    "Para a realiza√ß√£o das experi√™ncias de treino de modelos de aprendizagem autom√°tica, foram consultados diversos recursos online com o objetivo de compreender boas pr√°ticas no pr√©-processamento de texto, vetoriza√ß√£o de dados e aplica√ß√£o de modelos supervisionados. As principais fontes foram:\n",
    "\n",
    "- [Scikit-learn: Text classification tutorial](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html) ‚Äî Guia oficial do scikit-learn para classifica√ß√£o de texto com TF-IDF e Logistic Regression.\n",
    "- [Scikit-learn: Feature extraction with text](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) ‚Äî Documenta√ß√£o oficial sobre vetoriza√ß√£o de texto.\n",
    "- [NLTK Documentation](https://www.nltk.org/) ‚Äî Refer√™ncia para tokeniza√ß√£o, stopwords e stemming com `nltk`.\n",
    "- [Towards Data Science - Text Classification using Scikit-Learn](https://towardsdatascience.com/text-classification-using-scikit-learn-f35828a9e37f) ‚Äî Artigo introdut√≥rio com exemplos pr√°ticos.\n",
    "- Stack Overflow ‚Äî V√°rios t√≥picos sobre boas pr√°ticas de limpeza de texto, tratamento de stopwords e performance com TF-IDF.\n",
    "\n",
    "As implementa√ß√µes foram adaptadas e organizadas de forma a garantir a clareza do c√≥digo, a separa√ß√£o por experi√™ncias, e a possibilidade de comparar diferentes estrat√©gias de pr√©-processamento.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
